{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8SEJVu11ExHl"
      },
      "source": [
        "# Auto Big-bench\n",
        "copyright 2024, Denis Rothman\n",
        "\n",
        "[Big-bench](https://github.com/google/BIG-bench/blob/main/bigbench/benchmark_tasks/README.md) contains more than 200+ NLP tasks. The goal is to evaluate a model.\n",
        "\n",
        "In this notebook, we take ChatGPT-GPT4 a step further. We will not ask ChatGPT-GPT-4 to solve a Big-bench NLP problem and apply metrics. We will ask GPT-4 to create the tasks itself and solve them!\n",
        "\n",
        "*The potential of the next generation of AI might be able to evaluate and benchmark itself.*\n",
        "\n",
        "The program will feed GPT-4 a sample of 140+ Big-bench tasks with a two-part prompt:   \n",
        "\n",
        "**The first part contains the instruction:**    \n",
        "\n",
        "**The second part is the description of a Big-bench:**  \n",
        "\n",
        "**The output will then be displayed for human evaluation**\n",
        "Human evaluation plays an important role in LLM training and evaluations. Reinforcement Learning with Human Feedback(RLHF) will help mitigate the potential limits of automated models and evaluation metrics.\n",
        "\n",
        "**Limit of the program:** The program does not run thousands of samples for each task. The goal is to show the potential of Large Language Models(LLMs)\n",
        "\n",
        "**Potential:** We can see that GPT-4, PaLM 2, and other Foundations Models are just the beginning of what will become *Massive Multitask Language Understanding(MMLU)* models in one form or another in the years to come.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "byQGn0JqOJKH"
      },
      "source": [
        "# Install OpenAI\n",
        "\n",
        "Note:\n",
        "OpenAI in January 2024 requires dependencies that in turn require other dependencies that are installed after or before. On Google Colab(or your machine), if you encounter OpenAI installation issues, try the process below:  \n",
        "a) uncomment and install cohere and run it after the `!pip install openai` cell<br>\n",
        "b) uncomment and install tiktoken and run it after `!pip install cohere `  \n",
        "c) then run `!pip install cohere ` again   \n",
        "d) then run `!pip install openai` again   \n",
        "\n",
        "Hopefully, OpenAI will fix this in 2024 and we will update the installation accordingly. This is normal on a fast-moving market. We simply need to be on the watch."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AqoVOwBGv3rk",
        "outputId": "ce727896-5ff1-4067-be26-7b8aef2ca7f0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting openai\n",
            "  Downloading openai-1.9.0-py3-none-any.whl (223 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m223.4/223.4 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai) (1.7.0)\n",
            "Collecting httpx<1,>=0.23.0 (from openai)\n",
            "  Downloading httpx-0.26.0-py3-none-any.whl (75 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.9/75.9 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai) (1.10.13)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai) (1.3.0)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.1)\n",
            "Collecting typing-extensions<5,>=4.7 (from openai)\n",
            "  Downloading typing_extensions-4.9.0-py3-none-any.whl (32 kB)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (3.6)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (1.2.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (2023.11.17)\n",
            "Collecting httpcore==1.* (from httpx<1,>=0.23.0->openai)\n",
            "  Downloading httpcore-1.0.2-py3-none-any.whl (76 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.9/76.9 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting h11<0.15,>=0.13 (from httpcore==1.*->httpx<1,>=0.23.0->openai)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: typing-extensions, h11, httpcore, httpx, openai\n",
            "  Attempting uninstall: typing-extensions\n",
            "    Found existing installation: typing_extensions 4.5.0\n",
            "    Uninstalling typing_extensions-4.5.0:\n",
            "      Successfully uninstalled typing_extensions-4.5.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "llmx 0.0.15a0 requires cohere, which is not installed.\n",
            "llmx 0.0.15a0 requires tiktoken, which is not installed.\n",
            "tensorflow-probability 0.22.0 requires typing-extensions<4.6.0, but you have typing-extensions 4.9.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed h11-0.14.0 httpcore-1.0.2 httpx-0.26.0 openai-1.9.0 typing-extensions-4.9.0\n"
          ]
        }
      ],
      "source": [
        "#Importing openai\n",
        "!pip install openai"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VW5WQx6hR3Zv"
      },
      "outputs": [],
      "source": [
        "#!pip install cohere"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oLtZDy2XnMZ1"
      },
      "outputs": [],
      "source": [
        "#!pip install tiktoken"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pvIVVNr0OMMI"
      },
      "outputs": [],
      "source": [
        "#The OpenAI Key\n",
        "import openai\n",
        "import os\n",
        "os.environ['OPENAI_API_KEY'] =[YOUR_KEY]\n",
        "openai.api_key = os.getenv(\"OPENAI_API_KEY\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NYTZAY_MHL8h"
      },
      "source": [
        "# Retrieve the list of Big-bench prompts designed for this notebook\n",
        "\n",
        "The list was created from the list of tasks of [Big-bench](https://github.com/google/BIG-bench/blob/main/bigbench/benchmark_tasks/README.md)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VoORGkR_J19Q",
        "outputId": "b39ffd1c-264b-4afc-ba60-409be909b7fb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100 17838  100 17838    0     0  79400      0 --:--:-- --:--:-- --:--:-- 79633\n"
          ]
        }
      ],
      "source": [
        "!curl -L https://raw.githubusercontent.com/Denis2054/Transformers_3rd_Edition/master/Chapter15/tasks.txt --output \"tasks.txt\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RYQsYeB2KZMl"
      },
      "source": [
        "# Read the file into a Pandas Dataframe"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "4QQbTTeIKe7u",
        "outputId": "0363d3f2-0c10-4226-bde0-8cbb5341945d"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-d38d885f-17fb-406c-b651-435c5f4a5d52\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Tasks</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1.Explain the following task 2.Provide an exam...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1.Explain the following task 2.Provide an exam...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1.Explain the following task 2.Provide an exam...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1.Explain the following task 2.Provide an exam...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1.Explain the following task 2.Provide an exam...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>139</th>\n",
              "      <td>1.Explain the following task 2.Provide an exam...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>140</th>\n",
              "      <td>1.Explain the following task 2.Provide an exam...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>141</th>\n",
              "      <td>1.Explain the following task 2.Provide an exam...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>142</th>\n",
              "      <td>1.Explain the following task 2.Provide an exam...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>143</th>\n",
              "      <td>1.Explain the following task 2.Provide an exam...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>144 rows × 1 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d38d885f-17fb-406c-b651-435c5f4a5d52')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-d38d885f-17fb-406c-b651-435c5f4a5d52 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-d38d885f-17fb-406c-b651-435c5f4a5d52');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-1b58c2be-b88c-46d2-bc9f-5d4ae2f37bcc\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-1b58c2be-b88c-46d2-bc9f-5d4ae2f37bcc')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-1b58c2be-b88c-46d2-bc9f-5d4ae2f37bcc button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "                                                 Tasks\n",
              "0    1.Explain the following task 2.Provide an exam...\n",
              "1    1.Explain the following task 2.Provide an exam...\n",
              "2    1.Explain the following task 2.Provide an exam...\n",
              "3    1.Explain the following task 2.Provide an exam...\n",
              "4    1.Explain the following task 2.Provide an exam...\n",
              "..                                                 ...\n",
              "139  1.Explain the following task 2.Provide an exam...\n",
              "140  1.Explain the following task 2.Provide an exam...\n",
              "141  1.Explain the following task 2.Provide an exam...\n",
              "142  1.Explain the following task 2.Provide an exam...\n",
              "143  1.Explain the following task 2.Provide an exam...\n",
              "\n",
              "[144 rows x 1 columns]"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# read the file\n",
        "df = pd.read_csv('tasks.txt', header=None, on_bad_lines='skip')\n",
        "\n",
        "# If you want to add a column name after loading\n",
        "df.columns = ['Tasks']\n",
        "\n",
        "# print the dataframe\n",
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "el3DyGEFQO9u",
        "outputId": "ebcce2e0-04d6-42a0-ed50-2cbc2b6eb417"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of tasks:  144\n"
          ]
        }
      ],
      "source": [
        "nbt=len(df)\n",
        "print(\"Number of tasks: \", nbt)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jYVtR5MsOy9R"
      },
      "source": [
        "# Defining the rolel of the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "34f9D9dxO4U9"
      },
      "outputs": [],
      "source": [
        "import openai\n",
        "from openai import OpenAI\n",
        "\n",
        "client = OpenAI()\n",
        "gptmodel=\"gpt-4-turbo\" # or select gpt-3.5-turbo\n",
        "\n",
        "def openai_chat(input_text):\n",
        "    response = client.chat.completions.create(\n",
        "        model=gptmodel,\n",
        "        messages=[\n",
        "            {\"role\": \"system\", \"content\": \"You are an expert Natural Language Processing exercise expert.\"},\n",
        "            {\"role\": \"assistant\", \"content\": \"1.You can explain any NLP task. 2.Create an example 3.Solve the example\"},\n",
        "            {\"role\": \"user\", \"content\": input_text}\n",
        "        ],\n",
        "        temperature=0.1  # Add the temperature parameter here and other parameters you need\n",
        "    )\n",
        "    return response.choices[0].message.content"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D0z5i0tNXxfD"
      },
      "source": [
        "# Displaying the response of the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KlddjhdiVn6f"
      },
      "outputs": [],
      "source": [
        "from IPython.core.display import display, HTML\n",
        "def display_response(input_text, response, bb_task):\n",
        "  html_content = f\"\"\"\n",
        "  <!DOCTYPE html>\n",
        "  <html>\n",
        "  <head>\n",
        "      <title>Big-bench Tasks</title>\n",
        "      <style>\n",
        "        p {{\n",
        "            max-width: 600px;\n",
        "        }}\n",
        "    </style>\n",
        "  </head>\n",
        "  <body>\n",
        "      <h1>{bb_task}</h1>\n",
        "      <p>{task}</p>\n",
        "  </body>\n",
        "  </html>\n",
        "  \"\"\"\n",
        "\n",
        "  # And finally we display it\n",
        "  display(HTML(html_content))\n",
        "  html_file = open(\"output.html\", \"a\")\n",
        "  html_file.write(html_content)\n",
        "  html_file.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OgSWHSlMhCfq"
      },
      "outputs": [],
      "source": [
        "html_file = open(\"output.html\", \"w\") #just to make sure a new file is created before running the tasks to avoid\n",
        "html_file.close()                    #processing large files."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7TINCE3hP3k7"
      },
      "source": [
        "# Running the tasks\n",
        "\n",
        "Check OpenAI's policy for rate limits before running the tasks:\n",
        "https://platform.openai.com/docs/guides/rate-limits/overview\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "JK8dkMOMjEPY",
        "outputId": "3a30a1b9-5ecb-4c4d-b71a-339007b796ac"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <!DOCTYPE html>\n",
              "  <html>\n",
              "  <head>\n",
              "      <title>Big-bench Tasks</title>\n",
              "      <style>\n",
              "        p {\n",
              "            max-width: 600px;\n",
              "        }\n",
              "    </style>\n",
              "  </head>\n",
              "  <body>\n",
              "      <h1>Given a narrative choose the most related proverb</h1>\n",
              "      <p>1. Explanation:<br>The task you're referring to is a form of text classification, specifically a type of semantic similarity task. In Natural Language Processing (NLP), semantic similarity is the process of understanding and determining how similar two pieces of text are in terms of meaning. In this case, the task is to determine which proverb is most semantically similar to a given narrative.<br><br>2. Example:<br>Let's take the narrative: \"A young boy worked hard all summer on his father's farm, waking up at the crack of dawn and working till sunset. Despite the hard work, he felt satisfied and content.\"<br><br>And the proverbs to choose from are:<br>a) \"Actions speak louder than words.\"<br>b) \"Don't count your chickens before they hatch.\"<br>c) \"The early bird catches the worm.\"<br><br>3. Solution:<br>In this case, the most related proverb to the narrative would be \"The early bird catches the worm.\" This proverb is the most semantically similar to the narrative as it also talks about waking up early and working hard, which is what the young boy in the narrative does. <br><br>To solve this using NLP, we could use a semantic similarity model like BERT or Word2Vec to convert the narrative and the proverbs into vector representations, and then calculate the cosine similarity between the narrative and each proverb. The proverb with the highest cosine similarity score would be the one most related to the narrative.</p>\n",
              "  </body>\n",
              "  </html>\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "\n",
              "  <!DOCTYPE html>\n",
              "  <html>\n",
              "  <head>\n",
              "      <title>Big-bench Tasks</title>\n",
              "      <style>\n",
              "        p {\n",
              "            max-width: 600px;\n",
              "        }\n",
              "    </style>\n",
              "  </head>\n",
              "  <body>\n",
              "      <h1>Solve tasks from Abstraction and Reasoning Corpus</h1>\n",
              "      <p>1. Explanation of the Task:<br><br>The Abstraction and Reasoning Corpus (ARC) is a dataset created by François Chollet (the creator of Keras) for measuring the reasoning abilities of AI models. The dataset consists of a training set and a test set of tasks that require various forms of reasoning to solve. Each task is a small, abstract, grid-based puzzle that requires understanding the underlying rules to solve. The tasks are designed to be solvable by humans in a few minutes.<br><br>2. Example:<br><br>A typical task in the ARC might look like this:<br><br>Input:<br>```<br>[[0, 0, 0, 0, 0],<br> [0, 0, 0, 0, 0],<br> [0, 0, 1, 0, 0],<br> [0, 0, 0, 0, 0],<br> [0, 0, 0, 0, 0]]<br>```<br><br>Output:<br>```<br>[[0, 0, 1, 0, 0],<br> [0, 0, 1, 0, 0],<br> [1, 1, 1, 1, 1],<br> [0, 0, 1, 0, 0],<br> [0, 0, 1, 0, 0]]<br>```<br><br>In this task, the rule is to extend the single '1' in the input grid to form a cross in the output grid.<br><br>3. Solving the Task:<br><br>Solving tasks from the ARC requires identifying the underlying rule or pattern that transforms the input grid to the output grid. This can be done using various machine learning techniques, such as convolutional neural networks or transformers, trained on the task examples in the ARC.<br><br>However, it's important to note that the ARC is designed to be challenging for current AI models, and many tasks in the ARC may not be solvable with current techniques. The goal of the ARC is to encourage the development of new models and techniques that can better handle abstract reasoning tasks.</p>\n",
              "  </body>\n",
              "  </html>\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "\n",
              "  <!DOCTYPE html>\n",
              "  <html>\n",
              "  <head>\n",
              "      <title>Big-bench Tasks</title>\n",
              "      <style>\n",
              "        p {\n",
              "            max-width: 600px;\n",
              "        }\n",
              "    </style>\n",
              "  </head>\n",
              "  <body>\n",
              "      <h1>Identify whether a given statement contains an anachronism</h1>\n",
              "      <p>1. Explanation:<br>An anachronism is a chronological inconsistency in some arrangement, especially a juxtaposition of persons, events, objects, language terms and customs from different time periods. In the context of Natural Language Processing (NLP), identifying an anachronism would involve determining if a given statement contains elements that do not fit within the time period it is supposed to represent.<br><br>2. Example:<br>Let's consider the following sentence: \"In 1920, John sent an email to his friend.\"<br><br>3. Solution:<br>To solve this task, we would need to have knowledge of the historical timeline of technology. We know that email was not in use in 1920. Therefore, the statement \"In 1920, John sent an email to his friend\" contains an anachronism.</p>\n",
              "  </body>\n",
              "  </html>\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "\n",
              "  <!DOCTYPE html>\n",
              "  <html>\n",
              "  <head>\n",
              "      <title>Big-bench Tasks</title>\n",
              "      <style>\n",
              "        p {\n",
              "            max-width: 600px;\n",
              "        }\n",
              "    </style>\n",
              "  </head>\n",
              "  <body>\n",
              "      <h1>Identify the type of analogy between two events</h1>\n",
              "      <p>1. Explanation of the Task:<br><br>The task of identifying the type of analogy between two events involves understanding the relationship between two different situations or events and categorizing the type of analogy. An analogy is a comparison between two things, typically for the purpose of explanation or clarification. It's a cognitive process of transferring information or meaning from a particular subject to another. In this case, the subject is events. <br><br>There are several types of analogies, including:<br><br>- Proportional Analogies: A is to B as C is to D (e.g., hand is to glove as foot is to sock)<br>- Cause-Effect Analogies: A leads to B as C leads to D (e.g., smoking leads to lung cancer as overeating leads to obesity)<br>- Part-Whole Analogies: A is part of B as C is part of D (e.g., a petal is part of a flower as a tire is part of a car)<br>- Item-Category Analogies: A is a B as C is a D (e.g., a dog is a mammal as a rose is a plant)<br><br>2. Example:<br><br>Consider the following two events:<br><br>Event 1: A student studied hard and got an A on the test.<br>Event 2: A runner trained intensively and won the race.<br><br>3. Solution:<br><br>The analogy between these two events is a Cause-Effect Analogy. In both cases, the hard work and preparation (cause) led to a successful outcome (effect). The student's studying resulted in a high test score, and the runner's training led to a race victory.</p>\n",
              "  </body>\n",
              "  </html>\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "\n",
              "  <!DOCTYPE html>\n",
              "  <html>\n",
              "  <head>\n",
              "      <title>Big-bench Tasks</title>\n",
              "      <style>\n",
              "        p {\n",
              "            max-width: 600px;\n",
              "        }\n",
              "    </style>\n",
              "  </head>\n",
              "  <body>\n",
              "      <h1>Identify whether one sentence entails the next</h1>\n",
              "      <p>1. Explanation:<br>The task you're referring to is known as Natural Language Inference (NLI), also known as Textual Entailment. In this task, the goal is to determine if a given statement (the \"hypothesis\") can logically be inferred from another statement (the \"premise\"). There are typically three possible outcomes: the hypothesis can be entailed by the premise, it can contradict the premise, or it can be neutral (neither entailed nor contradicted).<br><br>2. Example:<br>Let's take an example:<br>Premise: \"The man is eating a piece of bread.\"<br>Hypothesis: \"The man is eating.\"<br><br>3. Solution:<br>In this case, the hypothesis \"The man is eating\" is entailed by the premise \"The man is eating a piece of bread.\" This is because if the man is eating a piece of bread, it is necessarily true that he is eating. Therefore, the relationship between the premise and the hypothesis is one of entailment.</p>\n",
              "  </body>\n",
              "  </html>\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import time\n",
        "\n",
        "counter = 0\n",
        "nb_tasks = nbt\n",
        "for index, row in df.iterrows():\n",
        "    input_text = row['Tasks']                 # the complete prompt\n",
        "    counter += 1                              # task counter\n",
        "    if counter > nb_tasks:\n",
        "        break                                 # nb of tasks\n",
        "    task = openai_chat(input_text)            # model call\n",
        "    task = task.replace('\\n', '<br>')         # formatting the output\n",
        "    parts = input_text.split('Solve it:')     # extracting the task from the input\n",
        "    bb_task = parts[1].strip()                # The strip() function\n",
        "    display_response(input_text, task, bb_task) # displaying the task and response\n",
        "\n",
        "    if counter % 50 == 0:                     # if the counter is divisible by 50\n",
        "        print(f\"Processed {counter} tasks. Pausing for 60 seconds.\")\n",
        "        time.sleep(60)                        # pause for 60 seconds"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}