{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BPM-W5IVxfJS"
      },
      "source": [
        "# Getting Started with GPT-4 API\n",
        "\n",
        "copyright 2024 Denis Rothman\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##April 29,2024 update to from gpt-4 to gpt-4-turbo\n",
        "\n",
        "OpenAI released gpt-4-turbo which is now deployed in this notebook\n",
        "\n",
        "https://platform.openai.com/docs/models/gpt-4-turbo-and-gpt-4"
      ],
      "metadata": {
        "id": "8PU-h5KBfC9q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "gmodel=\"gpt-4-turbo\""
      ],
      "metadata": {
        "id": "tgmfacEBfNMa"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import Image     #This is used for rendering images in the notebook"
      ],
      "metadata": {
        "id": "1yf-ju9P62Zb"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q7HO_zOAaA-Y"
      },
      "source": [
        "## Step 1: Installing & importing OpenAI"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tiktoken"
      ],
      "metadata": {
        "id": "fdfE-07V_jzx",
        "outputId": "e76fdcba-7351-40e1-abab-4c3ed127d8df",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tiktoken in /usr/local/lib/python3.10/dist-packages (0.6.0)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken) (2023.12.25)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.10/dist-packages (from tiktoken) (2.31.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (2024.2.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install cohere"
      ],
      "metadata": {
        "id": "_8Uzj4_w_lea",
        "outputId": "317d5c12-8afc-4782-dc54-4f372a4c6ce0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: cohere in /usr/local/lib/python3.10/dist-packages (5.3.3)\n",
            "Requirement already satisfied: fastavro<2.0.0,>=1.9.4 in /usr/local/lib/python3.10/dist-packages (from cohere) (1.9.4)\n",
            "Requirement already satisfied: httpx>=0.21.2 in /usr/local/lib/python3.10/dist-packages (from cohere) (0.27.0)\n",
            "Requirement already satisfied: httpx-sse<0.5.0,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from cohere) (0.4.0)\n",
            "Requirement already satisfied: pydantic>=1.9.2 in /usr/local/lib/python3.10/dist-packages (from cohere) (2.7.0)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from cohere) (2.31.0)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from cohere) (0.19.1)\n",
            "Requirement already satisfied: types-requests<3.0.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from cohere) (2.31.0.20240406)\n",
            "Requirement already satisfied: typing_extensions>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from cohere) (4.11.0)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx>=0.21.2->cohere) (3.7.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx>=0.21.2->cohere) (2024.2.2)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx>=0.21.2->cohere) (1.0.5)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.10/dist-packages (from httpx>=0.21.2->cohere) (3.7)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx>=0.21.2->cohere) (1.3.1)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx>=0.21.2->cohere) (0.14.0)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic>=1.9.2->cohere) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.18.1 in /usr/local/lib/python3.10/dist-packages (from pydantic>=1.9.2->cohere) (2.18.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.0.0->cohere) (3.3.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.0.0->cohere) (2.0.7)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.10/dist-packages (from tokenizers<0.20,>=0.19->cohere) (0.20.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers<0.20,>=0.19->cohere) (3.13.4)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers<0.20,>=0.19->cohere) (2023.6.0)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers<0.20,>=0.19->cohere) (4.66.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers<0.20,>=0.19->cohere) (6.0.1)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers<0.20,>=0.19->cohere) (24.0)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx>=0.21.2->cohere) (1.2.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qS_Qk62FxclT"
      },
      "source": [
        "try:\n",
        "  import openai\n",
        "except:\n",
        "  !pip install openai\n",
        "  import openai"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 1-April 29,2024 update to gpt-4-turbo\n",
        "\n",
        "OpenAI released gpt-4-turbo which is now deployed in this notebook\n",
        "\n",
        "https://platform.openai.com/docs/models/gpt-4-turbo-and-gpt-4"
      ],
      "metadata": {
        "id": "VgOk3qYjRwbV"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gnKbbxVMaYqy"
      },
      "source": [
        "## Step 2: Entering the API KEY"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "21LhKHnrxA5l",
        "outputId": "eda23507-756f-4045-9aa2-f43a79b91155",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "f = open(\"drive/MyDrive/files/api_key.txt\", \"r\")\n",
        "API_KEY=f.readline()\n",
        "f.close()"
      ],
      "metadata": {
        "id": "k8cmujpyxKjj"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Authentification\n",
        "\n",
        "Setting the environment variable OPENAI_API_KEY to the value of API_KEY"
      ],
      "metadata": {
        "id": "PTD5NZ4Ox-G4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ['OPENAI_API_KEY'] =API_KEY\n",
        "openai.api_key = os.getenv(\"OPENAI_API_KEY\")"
      ],
      "metadata": {
        "id": "NAzxa-GRx8Ip"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a6d0bggZX_dw"
      },
      "source": [
        "## Step 3: Running an NLP tasks with the default parameters\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NKwqIwACcB2B"
      },
      "source": [
        "## Step 4: Example 1: Grammar correction\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8pkZrsEzzNwS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9cc83895-8a61-49c8-d7dc-3132b1d22a0d"
      },
      "source": [
        "from openai import OpenAI\n",
        "client = OpenAI()\n",
        "\n",
        "response = client.chat.completions.create(\n",
        "  model=gmodel,\n",
        "  messages=[\n",
        "    {\n",
        "      \"role\": \"system\",\n",
        "      \"content\": \"You will be provided with statements, and your task is to convert them to standard English.\"\n",
        "    },\n",
        "    {\n",
        "      \"role\": \"user\",\n",
        "      \"content\": \"She no went to the market.\"\n",
        "    }\n",
        "  ],\n",
        "  temperature=0,\n",
        "  max_tokens=256,\n",
        "  top_p=1,\n",
        "  frequency_penalty=0,\n",
        "  presence_penalty=0\n",
        ")\n",
        "print(response.choices[0].message.content)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "She didn't go to the market.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hh1AuRliZVfS"
      },
      "source": [
        "## Example 2: Translation\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GlRVPjEMBBI2",
        "outputId": "b6b65141-4687-4458-8b3f-ead83ece572c"
      },
      "source": [
        "from openai import OpenAI\n",
        "client = OpenAI()\n",
        "\n",
        "response = client.chat.completions.create(\n",
        "  model=gmodel,\n",
        "  messages=[\n",
        "    {\n",
        "      \"role\": \"system\",\n",
        "      \"content\": \"You will be provided with sentences, and your task translate from English into French.\"\n",
        "    },\n",
        "    {\n",
        "      \"role\": \"user\",\n",
        "      \"content\": \"She did not go to the market.\"\n",
        "    }\n",
        "  ],\n",
        "  temperature=0,\n",
        "  max_tokens=256,\n",
        "  top_p=1,\n",
        "  frequency_penalty=0,\n",
        "  presence_penalty=0\n",
        ")\n",
        "print(response.choices[0].message.content)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Elle n'est pas allée au marché.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7KMUpe35ZA-t"
      },
      "source": [
        "## Example 3: Time Complexity\n",
        "\n",
        "https://platform.openai.com/examples/default-time-complexity"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from openai import OpenAI\n",
        "client = OpenAI()\n",
        "\n",
        "response = client.chat.completions.create(\n",
        "  model=gmodel,\n",
        "  messages=[\n",
        "    {\n",
        "      \"role\": \"system\",\n",
        "      \"content\": \"You will be provided with Python code, and your task is to calculate its time complexity.\"\n",
        "    },\n",
        "    {\n",
        "      \"role\": \"user\",\n",
        "      \"content\": \"def foo(n, k):\\n        accum = 0\\n        for i in range(n):\\n            for l in range(k):\\n                accum += i\\n        return accum\"\n",
        "    }\n",
        "  ],\n",
        "  temperature=0,\n",
        "  max_tokens=256,\n",
        "  top_p=1,\n",
        "  frequency_penalty=0,\n",
        "  presence_penalty=0\n",
        ")\n",
        "print(response.choices[0].message.content)"
      ],
      "metadata": {
        "id": "2jYE2kxxQocx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c5165d3d-9203-4175-86e1-2e56b5a73ea6"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "To determine the time complexity of the function `foo(n, k)`, let's analyze the loops and operations inside the function:\n",
            "\n",
            "1. **Outer Loop**: The outer loop `for i in range(n)` iterates `n` times, where `n` is the input parameter.\n",
            "\n",
            "2. **Inner Loop**: Inside the outer loop, there is another loop `for l in range(k)`. This inner loop iterates `k` times for each iteration of the outer loop. Here, `k` is another input parameter.\n",
            "\n",
            "3. **Operation Inside Inner Loop**: Inside the inner loop, the operation `accum += i` is executed. This operation is a simple addition, which we can consider to have a constant time complexity, O(1).\n",
            "\n",
            "Now, let's calculate the total number of times the innermost operation is executed:\n",
            "\n",
            "- For each iteration of the outer loop (which runs `n` times), the inner loop runs `k` times. Therefore, the statement `accum += i` is executed `n * k` times.\n",
            "\n",
            "Thus, the overall time complexity of the function `foo(n, k)` is O(n * k), where `n` and `k` are the dimensions of the two nested loops. This complexity is a product\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SWGCjioUawKp"
      },
      "source": [
        "## Example 4: Text to emoji\n",
        "\n",
        "https://platform.openai.com/examples/default-emoji-translation\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from openai import OpenAI\n",
        "client = OpenAI()\n",
        "\n",
        "response = client.chat.completions.create(\n",
        "  model=gmodel,\n",
        "  messages=[\n",
        "    {\n",
        "      \"role\": \"system\",\n",
        "      \"content\": \"You will be provided with text, and your task is to translate it into emojis. Do not use any regular text. Do your best with emojis only.\"\n",
        "    },\n",
        "    {\n",
        "      \"role\": \"user\",\n",
        "      \"content\": \"Artificial intelligence is a technology with great promise.\"\n",
        "    }\n",
        "  ],\n",
        "  temperature=0.8,\n",
        "  max_tokens=256,\n",
        "  top_p=1,\n",
        "  frequency_penalty=0,\n",
        "  presence_penalty=0\n",
        ")\n",
        "print(response.choices[0].message.content)"
      ],
      "metadata": {
        "id": "-S7qedUIR7Mb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2dce8e5f-10d5-4cdf-be6f-7406522d8dd8"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🤖💡🌟🔮\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yrS3kT-ebaT9"
      },
      "source": [
        "## Example 5: Spreadsheet creator\n",
        "\n",
        "https://platform.openai.com/examples/default-spreadsheet-gen\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from openai import OpenAI\n",
        "client = OpenAI()\n",
        "\n",
        "response = client.chat.completions.create(\n",
        "  model=gmodel,\n",
        "  messages=[\n",
        "    {\n",
        "      \"role\": \"user\",\n",
        "      \"content\": \"Create a two-column CSV of top science fiction movies along with the year of release.\"\n",
        "    }\n",
        "  ],\n",
        "  temperature=0.5,\n",
        "  max_tokens=300,\n",
        "  top_p=1,\n",
        "  frequency_penalty=0,\n",
        "  presence_penalty=0\n",
        ")\n",
        "print(response.choices[0].message.content)"
      ],
      "metadata": {
        "id": "J3yGaCEdR49a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "728b953f-270a-4fec-911d-6f7f1d02bdac"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Here's a sample CSV format listing some top science fiction movies along with their year of release. Since I can't create actual files or use external tools to generate a downloadable file, I'll format the information in plain text which you can easily convert into a CSV format:\n",
            "\n",
            "```plaintext\n",
            "Title,Year\n",
            "\"Blade Runner\",1982\n",
            "\"2001: A Space Odyssey\",1968\n",
            "\"Star Wars: Episode IV - A New Hope\",1977\n",
            "\"The Matrix\",1999\n",
            "\"Inception\",2010\n",
            "\"Back to the Future\",1985\n",
            "\"Aliens\",1986\n",
            "\"Metropolis\",1927\n",
            "\"Terminator 2: Judgment Day\",1991\n",
            "\"Interstellar\",2014\n",
            "\"Arrival\",2016\n",
            "\"Ex Machina\",2014\n",
            "\"The Fifth Element\",1997\n",
            "\"Minority Report\",2002\n",
            "\"District 9\",2009\n",
            "\"Her\",2013\n",
            "\"Eternal Sunshine of the Spotless Mind\",2004\n",
            "\"Children of Men\",2006\n",
            "\"Gravity\",2013\n",
            "\"The Martian\",2015\n",
            "```\n",
            "\n",
            "To create a CSV file from this data:\n",
            "1. Copy the text above.\n",
            "2. Open a text editor (such as Notepad on Windows or TextEdit on macOS).\n",
            "3. Paste the copied text into the text editor.\n",
            "4. Save the file with a `.csv` extension, e.g., `top_scifi_movies.csv`.\n",
            "\n",
            "This file can then be\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zNY5uUu6ead0"
      },
      "source": [
        "## Example 6: Advanced Tweet classifier\n",
        "\n",
        "https://beta.openai.com/examples/default-tweet-classifier\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YDeD3FkbearQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cfed1641-1719-473a-d7e1-68c5811ba886"
      },
      "source": [
        "from openai import OpenAI\n",
        "client = OpenAI()\n",
        "\n",
        "response = client.chat.completions.create(\n",
        "  model=gmodel,\n",
        "  messages=[\n",
        "    {\n",
        "      \"role\": \"system\",\n",
        "      \"content\": \"You will be provided with a tweet, and your task is to classify its sentiment as positive, neutral, or negative.\"\n",
        "    },\n",
        "    {\n",
        "      \"role\": \"user\",\n",
        "      \"content\": \"I loved the new Batman movie!\"\n",
        "    }\n",
        "  ],\n",
        "  temperature=0,\n",
        "  max_tokens=256,\n",
        "  top_p=1,\n",
        "  frequency_penalty=0,\n",
        "  presence_penalty=0\n",
        ")\n",
        "print(response.choices[0].message.content)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "positive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i-Qiw1mjcmd6"
      },
      "source": [
        "## Example 7: Natural Language to SQL\n",
        "\n",
        "https://platform.openai.com/examples/default-sql-translate\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from openai import OpenAI\n",
        "client = OpenAI()\n",
        "\n",
        "response = client.chat.completions.create(\n",
        "  model=gmodel,\n",
        "  messages=[\n",
        "    {\n",
        "      \"role\": \"system\",\n",
        "      \"content\": \"Given the following SQL tables, your job is to write queries given a user’s request.\\n    \\n    CREATE TABLE Orders (\\n      OrderID int,\\n      CustomerID int,\\n      OrderDate datetime,\\n      OrderTime varchar(8),\\n      PRIMARY KEY (OrderID)\\n    );\\n    \\n    CREATE TABLE OrderDetails (\\n      OrderDetailID int,\\n      OrderID int,\\n      ProductID int,\\n      Quantity int,\\n      PRIMARY KEY (OrderDetailID)\\n    );\\n    \\n    CREATE TABLE Products (\\n      ProductID int,\\n      ProductName varchar(50),\\n      Category varchar(50),\\n      UnitPrice decimal(10, 2),\\n      Stock int,\\n      PRIMARY KEY (ProductID)\\n    );\\n    \\n    CREATE TABLE Customers (\\n      CustomerID int,\\n      FirstName varchar(50),\\n      LastName varchar(50),\\n      Email varchar(100),\\n      Phone varchar(20),\\n      PRIMARY KEY (CustomerID)\\n    );\"\n",
        "    },\n",
        "    {\n",
        "      \"role\": \"user\",\n",
        "      \"content\": \"Write a SQL query which computes the average total order value for all orders on 2023-04-01.\"\n",
        "    }\n",
        "  ],\n",
        "  temperature=0,\n",
        "  max_tokens=1024,\n",
        "  top_p=1,\n",
        "  frequency_penalty=0,\n",
        "  presence_penalty=0\n",
        ")\n",
        "print(response.choices[0].message.content)"
      ],
      "metadata": {
        "id": "qALmluVsWEnn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d700c71e-cd35-4b55-808a-e1a70ee5175c"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "To compute the average total order value for all orders on a specific date, we need to sum the products of quantities and unit prices for each order and then average these sums across all orders from that date. Here's the SQL query to achieve this:\n",
            "\n",
            "```sql\n",
            "SELECT AVG(TotalOrderValue) AS AvgTotalOrderValue\n",
            "FROM (\n",
            "    SELECT o.OrderID, SUM(od.Quantity * p.UnitPrice) AS TotalOrderValue\n",
            "    FROM Orders o\n",
            "    JOIN OrderDetails od ON o.OrderID = od.OrderID\n",
            "    JOIN Products p ON od.ProductID = p.ProductID\n",
            "    WHERE o.OrderDate = '2023-04-01'\n",
            "    GROUP BY o.OrderID\n",
            ") AS OrderValues;\n",
            "```\n",
            "\n",
            "This query works as follows:\n",
            "1. **Join Operations**: It joins the `Orders`, `OrderDetails`, and `Products` tables to relate each order with its details and the corresponding product prices.\n",
            "2. **WHERE Clause**: It filters the orders to include only those placed on '2023-04-01'.\n",
            "3. **GROUP BY Clause**: It groups the results by `OrderID` to calculate the total value for each individual order.\n",
            "4. **SUM Function**: It calculates the total value of each order by summing the products of the quantities and unit prices of all items in each order.\n",
            "5. **Subquery**: The inner query calculates the total value for each order and the outer query calculates the average of these total values.\n"
          ]
        }
      ]
    }
  ]
}